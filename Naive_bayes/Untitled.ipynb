{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=datasets.load_iris()\n",
    "x = pd.DataFrame(iris.data)\n",
    "x.columns = [\"sl\", \"sw\", 'pl', 'pw']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting the continious data into label data \n",
    "code copied from decision tree ML/extracthere/Assignment Decision Tree Sarthak/Decision_tree_assignment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a, b, c, d\n",
    "def toLabel(x, old_feature_name):\n",
    "    second = x[old_feature_name].mean()\n",
    "    minimum = x[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = x[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return x[old_feature_name].apply(label, args= (first, second, third))\n",
    "\n",
    "x[\"s_l\"]=toLabel(x,\"sl\")\n",
    "x[\"s_w\"]=toLabel(x,\"sw\")\n",
    "x[\"p_l\"]=toLabel(x,\"pl\")\n",
    "x[\"p_w\"]=toLabel(x,\"pw\")\n",
    "x.drop([\"sl\",\"sw\",\"pl\",\"pw\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sl sw pl pw\n",
       "0  b  c  a  a\n",
       "1  a  b  a  a\n",
       "2  a  c  a  a\n",
       "3  a  c  a  a\n",
       "4  a  c  a  a"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns = [\"sl\", \"sw\", 'pl', 'pw']\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(150, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sl', 'sw', 'pl', 'pw']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(x)\n",
    "print(len(arr[0]))\n",
    "print(arr.shape)\n",
    "(arr[:,0]=='a').sum()\n",
    "col_names = [\"sl\", \"sw\", 'pl', 'pw']\n",
    "col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT FUNCTION\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(xtrain,ytrain):\n",
    "    dic ={}\n",
    "    for curr_class in set(ytrain) :\n",
    "        dic[curr_class] ={}\n",
    "        dic[\"total_data\"] = len(ytrain)\n",
    "        \n",
    "        # current_class_rows will have a boolean array with true when the particular row belongs to that classs\n",
    "        current_class_rows = (ytrain==curr_class)\n",
    "        # xtrain_for_curr_class has only those xtrain for a particular class\n",
    "        xtrain_for_curr_class = xtrain[current_class_rows]\n",
    "        ytrain_for_curr_class = ytrain[current_class_rows]\n",
    "        # this stroes the length of that class ki total setosa kitna baaki kitne\n",
    "        dic[curr_class][\"total_count_of_each_class\"] = len(ytrain_for_curr_class)\n",
    "        \n",
    "        # har class ke liye saare feature like sl,pl... etc pe traverse kro\n",
    "        for j in range(xtrain.shape[1]):\n",
    "            dic[curr_class][col_names[j]] = {}\n",
    "            # all_values_a_feature_can_take will have all the distinct values a particular feature( like sepal length) \n",
    "            # for class 0 jaise sepal length can have a , b , c , d aise ..\n",
    "            all_values_a_feature_can_take =  set(xtrain[:,j])\n",
    "            \n",
    "            # now for every value a , b, c,d for each class and every feature kitne usme se a y b h store krdo\n",
    "            for distinct_value_of_feature in all_values_a_feature_can_take :    \n",
    "                dic[curr_class][col_names[j]][distinct_value_of_feature] = (xtrain_for_curr_class[:,j]==distinct_value_of_feature).sum()   \n",
    "          \n",
    "    return dic\n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProb(dic,x,curr_class) :\n",
    "    # formula P(y=a1)*p(xj=xj/y=a1)\n",
    "    # class_prob stores p(y=a1) \n",
    "    # for class 0 it the total class 0 is 40 and class 0 + class 1 + class2 = 100\n",
    "    # p(y=a1)  for class 0 will be 40/100\n",
    "    # 40 is stored in total_count_of_each_class and 100 in total_data\n",
    "    class_prob = np.log(dic[curr_class]['total_count_of_each_class']) - np.log(dic[\"total_data\"])\n",
    "    prob = class_prob\n",
    "    # we have subtracted 1 because we have added one column of total_count_of_each_class\n",
    "    num_of_features = len(dic[curr_class].keys()) - 1\n",
    "    for j in range(num_of_features) :\n",
    "        xj = x[j]\n",
    "        # p(xj=xj/y=ya1)*p(y=a1)\n",
    "        # now from above formula p(xj=xj/y=ya1) this equals to count where class =a1 and xj= xj which is stored in\n",
    "        # count_with_curr_class_value_xj \n",
    "        ### LAPLACE CORRECTION DONE BY ADDING ! TO NUM AND\n",
    "        ### COUNT OF DISTINCT VALUES EACH FEATURE CAN TAKE IN DENOMINARIOR\n",
    "        ### WHICH IS GOT BY FETCHING ALL THE KEYS FOR CURR CLASS , CURR FEATURE\n",
    "        count_with_curr_class_value_xj = dic[curr_class][col_names[j]][xj] + 1\n",
    "        curr_class_count = dic[curr_class]['total_count_of_each_class'] + len(dic[curr_class][col_names[j]].keys())\n",
    "        # p(xj=xj/y=ya1) = main_prob\n",
    "        main_prob = np.log(count_with_curr_class_value_xj)-np.log(curr_class_count)\n",
    "        prob = prob+main_prob\n",
    "    \n",
    "    return prob\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictForOne(dic,x):\n",
    "    classes = dic.keys()\n",
    "    # highest_prob stores like there is 33% chance that x belongs to class 0 and 40% chance that it belongs to class 1\n",
    "    # and 80% chance that it belongs to class 2 so highest_prob will store 80\n",
    "    highest_prob = -1000\n",
    "    predicted_class = -123\n",
    "    for curr_class in classes :\n",
    "        if(curr_class ==\"total_data\") :\n",
    "            continue\n",
    "        p_that_x_belongs_to_curr_class = getProb(dic,x,curr_class)\n",
    "        if(p_that_x_belongs_to_curr_class>highest_prob) :\n",
    "            highest_prob = p_that_x_belongs_to_curr_class\n",
    "            predicted_class = curr_class\n",
    "            \n",
    "    return predicted_class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dic,xtest) :\n",
    "    ypred=[]\n",
    "    for x in xtest:\n",
    "        x_class = PredictForOne(dic,x)\n",
    "        ypred.append(x_class)  \n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'total_count_of_each_class': 31, 'sl': {'c': 0, 'd': 0, 'b': 16, 'a': 15}, 'sw': {'c': 20, 'd': 8, 'b': 2, 'a': 1}, 'pl': {'c': 0, 'd': 0, 'b': 0, 'a': 31}, 'pw': {'c': 0, 'd': 0, 'b': 0, 'a': 31}}, 'total_data': 112, 1: {'total_count_of_each_class': 38, 'sl': {'c': 20, 'd': 2, 'b': 13, 'a': 3}, 'sw': {'c': 8, 'd': 0, 'b': 19, 'a': 11}, 'pl': {'c': 32, 'd': 0, 'b': 6, 'a': 0}, 'pw': {'c': 29, 'd': 0, 'b': 9, 'a': 0}}, 2: {'total_count_of_each_class': 43, 'sl': {'c': 25, 'd': 12, 'b': 5, 'a': 1}, 'sw': {'c': 13, 'd': 2, 'b': 23, 'a': 5}, 'pl': {'c': 18, 'd': 25, 'b': 0, 'a': 0}, 'pw': {'c': 14, 'd': 29, 'b': 0, 'a': 0}}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(np.array(x),iris.target)\n",
    "dic = fit(xtrain,ytrain)\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_prob = np.log(dic[curr_class]['total_count_of_each_class']) - np.log(dic[\"total_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict(dic,np.array(xtest))\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.95      0.90      0.92        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "[[19  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  2  5]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))\n",
    "print(confusion_matrix(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
