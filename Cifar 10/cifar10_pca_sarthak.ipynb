{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next 4 were given in sample template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.data_path = \"data/CIFAR-10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looing at shape of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### images is of shape 50000 ,32,32,3 means 50000 image hai 32*32 ki and 3 is rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since images are in mutlidimensiol array we need to convert it into 2d so 50000,32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images_train.reshape((50000, 3072))\n",
    "x_test  = images_test.reshape((10000, 3072))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing features by keeping 95% variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=0\n",
    "total=0\n",
    "while total<0.95:\n",
    "    total += pca.explained_variance_ratio_[k]\n",
    "    k += 1\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we know k should be 217 for 95% variance , We will again create pca object with n_components= 217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86027628,  0.58956777,  0.42062095, ...,  0.62929502,\n",
       "         0.7761025 ,  0.76742428],\n",
       "       [ 0.11152023, -0.20522094,  1.68161846, ...,  1.94699703,\n",
       "        -0.18685917,  0.96716032],\n",
       "       [ 1.03891411, -2.48917687, -0.77127413, ..., -0.7918517 ,\n",
       "         0.10204666, -0.55298249],\n",
       "       ...,\n",
       "       [ 0.09506512, -2.45038108, -0.11033342, ..., -0.0204035 ,\n",
       "         1.1420846 , -0.12777842],\n",
       "       [ 1.52781059, -0.72932918,  1.5590617 , ..., -0.98022143,\n",
       "         1.53383583, -0.99255869],\n",
       "       [ 0.56349842, -0.25582611, -1.24529006, ..., -0.25786515,\n",
       "        -0.23659761, -0.55400581]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=k,whiten=True)\n",
    "x_transformed = pca.fit_transform(x_train)\n",
    "x_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca = x_transformed\n",
    "x_test_pca = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating object of Random Forest \n",
    "prediction is worked by not on running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.53      1000\n",
      "           1       0.49      0.58      0.53      1000\n",
      "           2       0.34      0.29      0.32      1000\n",
      "           3       0.31      0.28      0.29      1000\n",
      "           4       0.41      0.40      0.41      1000\n",
      "           5       0.38      0.36      0.37      1000\n",
      "           6       0.48      0.52      0.50      1000\n",
      "           7       0.50      0.40      0.45      1000\n",
      "           8       0.53      0.60      0.56      1000\n",
      "           9       0.46      0.47      0.47      1000\n",
      "\n",
      "    accuracy                           0.45     10000\n",
      "   macro avg       0.44      0.45      0.44     10000\n",
      "weighted avg       0.44      0.45      0.44     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "cross_val_score(clf,x_train_pca,cls_train)\n",
    "clf.fit(x_train_pca, cls_train)\n",
    "y_pred = clf.predict(x_test_pca)\n",
    "print(classification_report(cls_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cls_test contains numbers like 3 ,2,1,8... and each index specifies a class like \n",
    "airplane 0 <br>\n",
    " 'automobile 1 <br>\n",
    " 'bird' 2 <br>\n",
    " 'cat' 3 and son on.... <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'ship', 'ship', ..., 'dog', 'automobile', 'horse'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=[]\n",
    "for i in cls_test :\n",
    "    ans.append(class_names[i])\n",
    "    \n",
    "np.array(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"cifar10_pred_sarthak.csv\",np.array(ans),fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
